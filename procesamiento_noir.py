import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import re
from typing import Dict, List, Tuple, Any
import warnings

# Suprimir warnings
warnings.filterwarnings('ignore')

# Constantes del sistema
INPUT_DIR = "img_noir"
OUTPUT_DIR = "output"
PROCESSED_DIR = "imagenes_procesadas_noir_avanzado"
CSV_PATH = os.path.join(OUTPUT_DIR, "metricas_reflectancia.csv")

# Par√°metros de segmentaci√≥n para hojas verdes en NIR
MIN_LEAF_AREA = 470       # √Årea m√≠nima para eliminar objetos muy peque√±os
MIN_STEM_AREA = 50           # √Årea m√≠nima para tallos
KERNEL_SIZE = 3              # Tama√±o del kernel para morfolog√≠a



def ensure_dirs():
    """Crear directorios de salida necesarios."""
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    os.makedirs(os.path.join(OUTPUT_DIR, PROCESSED_DIR), exist_ok=True)

def list_images(folder: str) -> List[str]:
    """Listar im√°genes en la carpeta especificada."""
    valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')
    images = []
    
    if os.path.exists(folder):
        for file in os.listdir(folder):
            if file.lower().endswith(valid_extensions):
                images.append(os.path.join(folder, file))
    
    return sorted(images)

def extract_timestamp(filename: str) -> str:
    """Extraer timestamp del nombre del archivo."""
    # Patr√≥n m√°s flexible para nombres como "foto_2025-08-27_16-00-10"
    timestamp_regex = r"(\d{4})[_\-\s]?(\d{2})[_\-\s]?(\d{2})[_\-\s]?(\d{2})[_\-\s]?(\d{2})[_\-\s]?(\d{2})"
    match = re.search(timestamp_regex, filename)
    
    if match:
        y, M, d, h, m, s = map(int, match.groups())
        return f"{y:04d}-{M:02d}-{d:02d} {h:02d}:{m:02d}:{s:02d}"
    
    # Si no coincide, intentar con patr√≥n m√°s simple
    simple_regex = r"(\d{4})[_\-\s](\d{2})[_\-\s](\d{2})"
    simple_match = re.search(simple_regex, filename)
    
    if simple_match:
        y, M, d = map(int, simple_match.groups())
        return f"{y:04d}-{M:02d}-{d:02d} 00:00:00"
    
    return "Sin timestamp"

def apply_advanced_preprocessing_nir(bgr: np.ndarray) -> np.ndarray:
    """
    Preprocesamiento avanzado para im√°genes NIR con enfoque en plantas verdes:
    - Balance de blancos Gray World
    - CLAHE para contraste en canal V
    - Ajuste de luminosidad para mejor detecci√≥n de hojas
    - Suavizado selectivo para preservar detalles de hojas
    """
    try:
        h, w = bgr.shape[:2]
        
        # 1. BALANCE DE BLANCOS GRAY WORLD (simplificado)
        # Convertir a float32 para c√°lculos
        bgr_float = bgr.astype(np.float32)
        b, g, r = bgr_float[:,:,0], bgr_float[:,:,1], bgr_float[:,:,2]
        
        # Calcular medias
        mb, mg, mr = np.mean(b) + 1e-6, np.mean(g) + 1e-6, np.mean(r) + 1e-6
        k = (mb + mg + mr) / 3.0
        
        # Aplicar balance
        b_balanced = np.clip(b * k/mb, 0, 255)
        g_balanced = np.clip(g * k/mg, 0, 255)
        r_balanced = np.clip(r * k/mr, 0, 255)
        
        # Reconstruir imagen
        bgr_balanced = np.stack([b_balanced, g_balanced, r_balanced], axis=2).astype(np.uint8)
        
        # 2. CLAHE PARA CONTRASTE EN CANAL V
        hsv = cv2.cvtColor(bgr_balanced, cv2.COLOR_BGR2HSV)
        h, s, v = hsv[:,:,0], hsv[:,:,1], hsv[:,:,2]
        
        # CLAHE solo en el canal V (brillo) para preservar colores
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        v_enhanced = clahe.apply(v)
        
        # 3. AJUSTE DE LUMINOSIDAD PARA MEJOR DETECCI√ìN DE HOJAS
        # Aumentar levemente la luminosidad del canal V para destacar hojas
        v_brightened = np.clip(v_enhanced * 1.15, 0, 255).astype(np.uint8)  # +15% de luminosidad
        
        # Reconstruir HSV con canal V mejorado y m√°s brillante
        hsv_enhanced = np.stack([h, s, v_brightened], axis=2)
        bgr_enhanced = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)
        
        # 4. SUAVIZADO SELECTIVO (bilateral filter para preservar bordes)
        bgr_smooth = cv2.bilateralFilter(bgr_enhanced, 9, 75, 75)
        
        return bgr_smooth
        
    except Exception as e:
        print(f"  ‚ö†Ô∏è Error en preprocesamiento avanzado NIR: {e}")
        # Fallback: imagen original
        return bgr

def define_plant_roi_noir(bgr: np.ndarray) -> Tuple[np.ndarray, List[Tuple[int, int, int]]]:
    """
    Define ROIs circulares adaptativos para plantas en im√°genes NIR.
    Combina detecci√≥n autom√°tica con coordenadas base como respaldo.
    """
    h, w = bgr.shape[:2]
    
    print("    üîß Usando ROIs adaptativos con detecci√≥n autom√°tica...")
    
    # Coordenadas base como respaldo (las originales)
    TAMANO_ESTANDAR_ROI = 63  # Tama√±o est√°ndar basado en esta imagen espec√≠fica
    
    # Coordenadas base para las dos macetas
    coordenadas_base = [
        (625, 295, TAMANO_ESTANDAR_ROI),  # Maceta superior (amarilla) - calibrada para maceta negra real
        (641, 455, TAMANO_ESTANDAR_ROI)   # Maceta inferior (rosada) - calibrada para maceta negra real
    ]
    
    print(f"       Coordenadas base:")
    print(f"         Maceta 1 (ARRIBA): centro(625, 295), radio={TAMANO_ESTANDAR_ROI}px")
    print(f"         Maceta 2 (ABAJO): centro(630, 455), radio={TAMANO_ESTANDAR_ROI}px")
    
    # DETECCI√ìN AUTOM√ÅTICA DE MACETAS
    macetas_detectadas = detect_automatic_pots(bgr, coordenadas_base)
    
    # CREACI√ìN DE ROIs
    roi_mask = np.zeros((h, w), dtype=np.uint8)
    roi_info = []
    
    for i, (cx, cy, radius) in enumerate(macetas_detectadas):
        # Asegurar que el c√≠rculo est√© dentro de los l√≠mites de la imagen
        center_x = max(radius, min(w - radius, cx))
        center_y = max(radius, min(h - radius, cy))
        
        # Dibujar c√≠rculo en la m√°scara
        cv2.circle(roi_mask, (center_x, center_y), radius, 255, -1)
        
        # Guardar informaci√≥n
        roi_info.append((center_x, center_y, radius))
        
        posicion = "ARRIBA" if i == 0 else "ABAJO"
        print(f"       Maceta {i+1} ({posicion}): centro({center_x}, {center_y}), radio={radius}px")
    
    print(f"    üìè ROIs creados: {len(roi_info)} c√≠rculos adaptativos")
    
    return roi_mask, roi_info

def detect_automatic_pots(bgr: np.ndarray, base_coordinates: List[Tuple[int, int, int]]) -> List[Tuple[int, int, int]]:
    """
    Detecta autom√°ticamente las macetas negras cerca de las coordenadas base conocidas.
    Usa las coordenadas originales como respaldo si la detecci√≥n falla.
    
    Args:
        bgr: Imagen en formato BGR
        base_coordinates: Lista de coordenadas base (cx, cy, radius)
    
    Returns:
        Lista de coordenadas ajustadas (cx, cy, radius)
    """
    h, w = bgr.shape[:2]
    
    print("     Detectando macetas autom√°ticamente...")
    
    # Convertir a escala de grises para detecci√≥n
    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)
    
    # Aplicar umbral para detectar objetos oscuros (macetas negras)
    # Las macetas negras tienen valores bajos en escala de grises
    _, mask_dark = cv2.threshold(gray, 80, 255, cv2.THRESH_BINARY_INV)
    
    # Encontrar contornos de objetos oscuros
    contours, _ = cv2.findContours(mask_dark, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    adjusted_coordinates = []
    
    for i, (base_cx, base_cy, base_radius) in enumerate(base_coordinates):
        posicion = "ARRIBA" if i == 0 else "ABAJO"
        print(f"       üîç Analizando Maceta {i+1} ({posicion})...")
        
        # Buscar contornos cerca de las coordenadas base
        best_contour = None
        best_score = 0
        search_radius = base_radius * 2  # Radio de b√∫squeda alrededor de las coordenadas base
        
        for contour in contours:
            # Calcular el centro del contorno
            M = cv2.moments(contour)
            if M["m00"] == 0:
                continue
                
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])
            
            # Verificar si est√° dentro del radio de b√∫squeda
            distance = np.sqrt((cx - base_cx)**2 + (cy - base_cy)**2)
            if distance > search_radius:
                continue
            
            # Calcular √°rea del contorno
            area = cv2.contourArea(contour)
            
            # Verificar que el √°rea sea razonable para una maceta
            expected_area = np.pi * base_radius**2
            area_ratio = area / expected_area
            
            # Calcular circularidad
            perimeter = cv2.arcLength(contour, True)
            if perimeter == 0:
                continue
            circularity = 4 * np.pi * area / (perimeter * perimeter)
            
            # Calcular puntuaci√≥n basada en:
            # 1. Distancia a coordenadas base (m√°s cerca = mejor)
            # 2. Circularidad (m√°s circular = mejor)
            # 3. Relaci√≥n de √°rea (m√°s cercana a 1 = mejor)
            distance_score = 1.0 / (1.0 + distance / base_radius)
            circularity_score = circularity
            area_score = 1.0 / (1.0 + abs(area_ratio - 1.0))
            
            total_score = distance_score * 0.4 + circularity_score * 0.4 + area_score * 0.2
            
            if total_score > best_score and circularity > 0.3 and 0.3 < area_ratio < 3.0:
                best_score = total_score
                best_contour = contour
        
        if best_contour is not None and best_score > 0.5:
            # Calcular el centro y radio del mejor contorno
            M = cv2.moments(best_contour)
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])
            
            # Calcular radio basado en el √°rea
            area = cv2.contourArea(best_contour)
            radius = int(np.sqrt(area / np.pi))
            
            # Asegurar que el radio est√© dentro de l√≠mites razonables
            radius = max(50, min(100, radius))
            
            adjusted_coordinates.append((cx, cy, radius))
            print(f"        Maceta {i+1} ({posicion}): detectada autom√°ticamente - centro({cx}, {cy}), radio={radius}px (score: {best_score:.2f})")
        else:
            # Usar coordenadas base como respaldo
            adjusted_coordinates.append((base_cx, base_cy, base_radius))
            print(f"        Maceta {i+1} ({posicion}): usando coordenadas base - centro({base_cx}, {base_cy}), radio={base_radius}px")
    
    print(f"    üîç Detecci√≥n autom√°tica completada: {len(adjusted_coordinates)} macetas analizadas")
    return adjusted_coordinates


def enhanced_green_segmentation_nir(gray_preprocessed: np.ndarray, roi_mask: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
    """
    Segmentaci√≥n multi-nivel usando m√∫ltiples umbrales de reflectancia NIR:
    - Prueba diferentes percentiles ( 90, 91.5)
    - Combina las mejores detecciones de cada nivel
    - Valida la calidad y cobertura de hojas
    - Mantiene la precisi√≥n sin introducir ruido
    """
    try:
        h, w = gray_preprocessed.shape[:2]
        
        # 0. AN√ÅLISIS PRELIMINAR DE LA IMAGEN PREPROCESADA
        mean_intensity = np.mean(gray_preprocessed)
        std_intensity = np.std(gray_preprocessed)
        
        print(f"     An√°lisis de imagen preprocesada: intensidad={mean_intensity:.1f}, desv_std={std_intensity:.1f}")
        
        # 1. AN√ÅLISIS DE REFLECTANCIA NIR DENTRO DEL ROI
        roi_coords = np.where(roi_mask > 0)
        if len(roi_coords[0]) == 0:
            print(f"     ROI vac√≠o, no se puede procesar")
            return np.zeros_like(gray_preprocessed), {}
        
        roi_intensities = gray_preprocessed[roi_coords[0], roi_coords[1]]
        
        if len(roi_intensities) == 0:
            print(f"     No hay intensidades en ROI")
            return np.zeros_like(gray_preprocessed), {}
        
        # 2. SEGMENTACI√ìN MULTI-NIVEL CON M√öLTIPLES UMBRALES
        print(f"    üîß Iniciando segmentaci√≥n multi-nivel...")
        
        # Definir percentiles a probar (de menos a m√°s estricto)
        percentiles = [ 88.8, 89,89.5, 89.8,90 , 91.5]
        masks_by_percentile = {}
        scores_by_percentile = {}
        
        for percentile in percentiles:
            try:
                # Calcular umbral para este percentil
                threshold = np.percentile(roi_intensities, percentile)
                
                # Crear m√°scara binaria
                mask_binary = cv2.threshold(gray_preprocessed, threshold, 255, cv2.THRESH_BINARY)[1]
                mask_roi = cv2.bitwise_and(mask_binary, roi_mask)
                
                # Postprocesamiento morfol√≥gico
                kernel = np.ones((3, 3), np.uint8)
                mask_clean = cv2.morphologyEx(mask_roi, cv2.MORPH_OPEN, kernel, iterations=1)
                mask_clean = cv2.morphologyEx(mask_clean, cv2.MORPH_CLOSE, kernel, iterations=2)
                mask_clean = cv2.dilate(mask_clean, kernel, iterations=1)
                
                # Filtrar por tama√±o y forma
                mask_filtered = clean_components_by_size_and_shape(mask_clean, MIN_LEAF_AREA)
                
                # Calcular m√©tricas de calidad
                total_pixels = np.count_nonzero(mask_filtered)
                coverage_percentage = total_pixels / mask_filtered.size * 100
                
                # Calcular puntuaci√≥n de calidad basada en:
                # 1. Cobertura (m√°s p√≠xeles = mejor, pero no excesivo)
                # 2. Consistencia del umbral (percentil m√°s alto = m√°s confiable)
                # 3. Relaci√≥n con intensidad media del ROI
                roi_mean = np.mean(roi_intensities)
                threshold_ratio = threshold / roi_mean if roi_mean > 0 else 1.0
                
                # Puntuaci√≥n de cobertura (√≥ptima entre 0.1% y 2%)
                coverage_score = 1.0 / (1.0 + abs(coverage_percentage - 0.5))
                
                # Puntuaci√≥n de confiabilidad (percentil m√°s alto = mejor)
                reliability_score = percentile / 100.0
                
                # Puntuaci√≥n de umbral (cerca de la media del ROI = mejor)
                threshold_score = 1.0 / (1.0 + abs(threshold_ratio - 1.2))
                
                # Puntuaci√≥n total ponderada
                total_score = coverage_score * 0.4 + reliability_score * 0.3 + threshold_score * 0.3
                
                masks_by_percentile[percentile] = mask_filtered
                scores_by_percentile[percentile] = {
                    'score': total_score,
                    'threshold': threshold,
                    'pixels': total_pixels,
                    'coverage': coverage_percentage,
                    'threshold_ratio': threshold_ratio
                }
                
                print(f"       Percentil {percentile}: umbral={threshold:.1f}, p√≠xeles={total_pixels}, cobertura={coverage_percentage:.3f}%, score={total_score:.3f}")
                
            except Exception as e:
                print(f"        Error en percentil {percentile}: {e}")
                continue
        
        if not masks_by_percentile:
            print(f"     No se pudo generar ninguna m√°scara v√°lida")
            return np.zeros_like(gray_preprocessed), {}
        
        # 3. SELECCI√ìN INTELIGENTE DE LA MEJOR COMBINACI√ìN
        print(f"    üîß Seleccionando mejor combinaci√≥n de umbrales...")
        
        # Ordenar por puntuaci√≥n
        sorted_percentiles = sorted(scores_by_percentile.keys(), 
                                  key=lambda p: scores_by_percentile[p]['score'], 
                                  reverse=True)
        
        # Tomar el mejor percentil como base
        best_percentile = sorted_percentiles[0]
        best_mask = masks_by_percentile[best_percentile]
        best_score = scores_by_percentile[best_percentile]
        
        print(f"       Mejor percentil: {best_percentile} (score: {best_score['score']:.3f})")
        
        # 4. COMBINACI√ìN INTELIGENTE CON OTROS UMBRALES
        combined_mask = best_mask.copy()
        additional_pixels = 0
        
        # Probar agregar p√≠xeles de otros percentiles si mejoran la cobertura
        for percentile in sorted_percentiles[1:]:
            if scores_by_percentile[percentile]['score'] > 0.6:  # Solo si es de buena calidad
                current_mask = masks_by_percentile[percentile]
                
                # Encontrar p√≠xeles adicionales que no est√©n en la m√°scara combinada
                additional_pixels_mask = cv2.bitwise_and(current_mask, cv2.bitwise_not(combined_mask))
                additional_pixels_count = np.count_nonzero(additional_pixels_mask)
                
                # Solo agregar si hay p√≠xeles adicionales significativos
                if additional_pixels_count > 50:  # M√≠nimo 50 p√≠xeles adicionales
                    combined_mask = cv2.bitwise_or(combined_mask, additional_pixels_mask)
                    additional_pixels += additional_pixels_count
                    print(f"       Agregando percentil {percentile}: +{additional_pixels_count} p√≠xeles")
        
        if additional_pixels > 0:
            print(f"       Total p√≠xeles adicionales agregados: {additional_pixels}")
        
        # 5. LIMPIEZA FINAL DE LA M√ÅSCARA COMBINADA
        final_mask = clean_components_by_size_and_shape(combined_mask, MIN_LEAF_AREA)
        
        # 6. AN√ÅLISIS DE RESULTADOS FINALES
        final_pixels = np.count_nonzero(final_mask)
        final_coverage = final_pixels / final_mask.size * 100
        
        analysis_results = {
            'best_percentile': best_percentile,
            'best_threshold': best_score['threshold'],
            'best_score': best_score['score'],
            'final_pixels': final_pixels,
            'final_coverage': final_coverage,
            'additional_pixels_added': additional_pixels,
            'percentiles_tested': list(percentiles),
            'scores_by_percentile': scores_by_percentile,
            'min_leaf_area': MIN_LEAF_AREA,
            'mean_intensity': float(mean_intensity),
            'std_intensity': float(std_intensity),
            'roi_pixels': len(roi_intensities),
            'roi_mean_intensity': float(np.mean(roi_intensities))
        }
        
        print(f"     Segmentaci√≥n multi-nivel completada:")
        print(f"       - Mejor percentil: {best_percentile} (umbral: {best_score['threshold']:.1f})")
        print(f"       - P√≠xeles finales: {final_pixels}")
        print(f"       - Cobertura final: {final_coverage:.3f}%")
        print(f"       - P√≠xeles adicionales: {additional_pixels}")
        
        return final_mask, analysis_results
        
    except Exception as e:
        print(f"   Error en segmentaci√≥n multi-nivel NIR: {e}")
        empty_mask = np.zeros_like(gray_preprocessed)
        empty_analysis = {
            'best_percentile': 0,
            'best_threshold': 0,
            'best_score': 0.0,
            'final_pixels': 0,
            'final_coverage': 0.0,
            'additional_pixels_added': 0,
            'percentiles_tested': [],
            'scores_by_percentile': {},
            'min_leaf_area': MIN_LEAF_AREA,
            'total_pixels': 0,
            'percentage': 0.0,
            'mean_intensity': 0.0,
            'std_intensity': 0.0,
            'roi_pixels': 0,
            'roi_mean_intensity': 0.0
        }
        return empty_mask, empty_analysis
        
    except Exception as e:
        print(f"  ‚ö†Ô∏è Error en segmentaci√≥n NIR: {e}")
        empty_mask = np.zeros_like(gray_preprocessed)
        empty_analysis = {
            'nir_threshold': 0,
            'min_leaf_area': MIN_LEAF_AREA,
            'total_pixels': 0,
            'percentage': 0.0,
            'mean_intensity': 0.0,
            'std_intensity': 0.0,
            'roi_pixels': 0,
            'roi_mean_intensity': 0.0
        }
        return empty_mask, empty_analysis
        
    except Exception as e:
        print(f"  ‚ö†Ô∏è Error en segmentaci√≥n mejorada NIR: {e}")
        empty_mask = np.zeros_like(bgr[:,:,0])
        empty_analysis = {
            'exg_threshold': 0,
            'hsv_ranges': {'h': (0, 0), 's': (0, 0), 'v': (0, 0)},
            'min_leaf_area': MIN_LEAF_AREA,
            'total_pixels': 0,
            'percentage': 0.0,
            'exg_mean': 0.0,
            'exg_std': 0.0,
            'hsv_flexible_used': False,
            'edges_detection': False,
            'morphology_kernel_size': 3
        }
        return empty_mask, empty_analysis

def clean_components_by_size_and_shape(mask: np.ndarray, min_area: int) -> np.ndarray:
    """
    Limpieza avanzada de componentes por tama√±o y forma usando contornos.
    Filtra por √°rea, circularidad y relaci√≥n de aspecto para mantener solo hojas v√°lidas.
    Optimizada para hojas grises en condiciones de luz adversas.
    MEJORADA PARA ELIMINAR OBJETOS MUY PEQUE√ëOS Y PUNTOS FALSOS VERDES.
    """
    # 1. LIMPIEZA MORFOL√ìGICA PREVIA PARA ELIMINAR RUIDO PEQUE√ëO
    # Usar kernel m√°s peque√±o para eliminar puntos muy peque√±os
    kernel_small = np.ones((2, 2), np.uint8)
    mask_cleaned = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_small, iterations=1)
    
    # 2. ENCONTRAR CONTORNOS EN LA M√ÅSCARA LIMPIA
    contours, _ = cv2.findContours(mask_cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not contours:
        return mask_cleaned
    
    mask_clean = np.zeros_like(mask_cleaned)
    
    # 3. FILTRADO INTELIGENTE POR TAMA√ëO Y FORMA
    for contour in contours:
        area = cv2.contourArea(contour)
        
        # FILTRO PRINCIPAL: √Årea m√≠nima estricta
        if area < min_area:
            continue
        
        # FILTRO SECUNDARIO: Para objetos muy peque√±os, aplicar criterios m√°s estrictos
        if area < 20:  # Objetos entre 5-20 p√≠xeles
            # Para objetos peque√±os, verificar que tengan forma de hoja real
            perimeter = cv2.arcLength(contour, True)
            if perimeter == 0:
                continue
                
            # Calcular circularidad
            circularity = 4 * np.pi * area / (perimeter * perimeter)
            
            # Calcular relaci√≥n de aspecto
            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = float(w) / float(h) if h > 0 else 0
            
            # CRITERIOS MUY ESTRICTOS para objetos peque√±os (eliminar puntos falsos)
            if not (0.20 <= circularity <= 0.80 and  # Circularidad m√°s restrictiva
                    0.40 <= aspect_ratio <= 2.5):      # Relaci√≥n de aspecto m√°s restrictiva
                continue
                
            # Verificar convexidad para objetos peque√±os
            hull = cv2.convexHull(contour)
            hull_area = cv2.contourArea(hull)
            solidity = area / (hull_area + 1e-6) if hull_area > 0 else 0
            
            if solidity < 0.70:  # Solidez muy alta para objetos peque√±os
                continue
        
        # Para objetos m√°s grandes (>20 p√≠xeles), usar criterios est√°ndar
        else:
            perimeter = cv2.arcLength(contour, True)
            if perimeter == 0:
                continue
                
            circularity = 4 * np.pi * area / (perimeter * perimeter)
            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = float(w) / float(h) if h > 0 else 0
            
            # Criterios est√°ndar para objetos grandes
            if not (0.15 <= circularity <= 0.85 and
                    0.30 <= aspect_ratio <= 3.5):
                continue
                
            hull = cv2.convexHull(contour)
            hull_area = cv2.contourArea(hull)
            solidity = area / (hull_area + 1e-6) if hull_area > 0 else 0
            
            if solidity < 0.60:
                continue
        
        # Si pasa todos los filtros, mantener el contorno
        cv2.fillPoly(mask_clean, [contour], 255)
    
    # 4. LIMPIEZA FINAL ADICIONAL
    # Aplicar una apertura final para eliminar cualquier ruido residual
    kernel_final = np.ones((3, 3), np.uint8)
    mask_final = cv2.morphologyEx(mask_clean, cv2.MORPH_OPEN, kernel_final, iterations=1)
    
    return mask_final

def calculate_ndvi_metrics_nir(mask_leaves: np.ndarray, original_bgr: np.ndarray) -> List[Dict[str, Any]]:
    """
    Calcula m√©tricas de reflectancia NDVI para cada hoja detectada en im√°genes NIR:
    - √Årea de la hoja
    - NDVI promedio
    - Desviaci√≥n est√°ndar del NDVI
    """
    contours, _ = cv2.findContours(mask_leaves, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    metrics_list = []
    
    # Convertir imagen a RGB para c√°lculo de NDVI
    rgb_image = cv2.cvtColor(original_bgr, cv2.COLOR_BGR2RGB)
    
    for contour in contours:
        area = cv2.contourArea(contour)
        if area < MIN_LEAF_AREA:
            continue
        
        # Crear m√°scara para esta hoja espec√≠fica
        leaf_mask = np.zeros_like(mask_leaves)
        cv2.fillPoly(leaf_mask, [contour], 255)
        
        # Extraer valores RGB solo de esta hoja
        rgb_values = rgb_image[leaf_mask > 0]
        
        if len(rgb_values) > 0:
            # Separar canales RGB
            r_values = rgb_values[:, 0].astype(np.float32)  # Canal Rojo
            nir_values = rgb_values[:, 1].astype(np.float32)  # Canal NIR (verde en RGB)
            
            # Calcular NDVI para cada p√≠xel: (NIR - R) / (NIR + R)
            # Evitar divisi√≥n por cero
            denominator = nir_values + r_values
            ndvi_values = np.where(denominator > 0, (nir_values - r_values) / denominator, 0)
            
            # Calcular estad√≠sticas NDVI
            ndvi_mean = float(np.mean(ndvi_values))
            ndvi_std = float(np.std(ndvi_values))
            
            metrics = {
                'area': float(area),
                'ndvi_mean': ndvi_mean,
                'ndvi_std': ndvi_std
            }
            
            metrics_list.append(metrics)
    
    return metrics_list

def save_comprehensive_visualization_nir(original_bgr: np.ndarray, 
                                        mask_plants: np.ndarray,
                                        mask_leaves: np.ndarray,
                                        roi_info: List[Tuple[int, int, int]],
                                        analysis_results: Dict[str, Any],
                                        leaf_metrics: Dict[str, Any],
                                        save_path: str) -> None:
    """Visualizaci√≥n de solo im√°genes del proceso completo de segmentaci√≥n NIR."""
    
    # Crear m√°scaras de color para visualizaci√≥n
    leaves_colored = np.zeros_like(original_bgr)
    leaves_colored[mask_leaves > 0] = (0, 255, 0)      # Verde para hojas
    
    # Tama√±o de figura optimizado para 6 im√°genes m√°s grandes
    fig = plt.figure(figsize=(24, 16), dpi=150)
    
    # 1. Imagen original
    ax1 = fig.add_subplot(2, 3, 1)
    ax1.imshow(cv2.cvtColor(original_bgr, cv2.COLOR_BGR2RGB))
    ax1.set_title("Imagen Original NIR", fontsize=16)
    ax1.axis("off")
    
    # 2. ROIs circulares adaptativos definidos
    ax2 = fig.add_subplot(2, 3, 2)
    roi_vis = original_bgr.copy()
    
    # Coordenadas base para referencia
    coordenadas_base = [
        (625, 295, 72),  # Maceta superior
        (640, 455, 72)   # Maceta inferior
    ]
    
    # Dibujar coordenadas base como c√≠rculos punteados (referencia)
    for i, (base_cx, base_cy, base_radius) in enumerate(coordenadas_base):
        color_base = (128, 128, 128)  # Gris para coordenadas base
        cv2.circle(roi_vis, (base_cx, base_cy), base_radius, color_base, 2, cv2.LINE_8, 0)
        # Etiqueta para coordenadas base
        posicion = "ARRIBA" if i == 0 else "ABAJO"
        label_base = f"Base {i+1} ({posicion})"
        cv2.putText(roi_vis, label_base, (base_cx - 50, base_cy + base_radius + 20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, color_base, 1)
    
    # Dibujar los ROIs circulares adaptativos detectados
    for i, (center_x, center_y, radius) in enumerate(roi_info):
        color = (0, 255, 255) if i == 0 else (255, 0, 255)  # Amarillo para arriba, Magenta para abajo
        cv2.circle(roi_vis, (center_x, center_y), radius, color, 4)
        # Agregar etiqueta de maceta con posici√≥n
        posicion = "ARRIBA" if i == 0 else "ABAJO"
        label = f"Maceta {i+1} ({posicion})"
        cv2.putText(roi_vis, label, (center_x - 50, center_y - radius - 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
    
    ax2.imshow(cv2.cvtColor(roi_vis, cv2.COLOR_BGR2RGB))
    ax2.set_title("ROIs Circulares Adaptativos (Base + Detectados)", fontsize=16)
    ax2.axis("off")
    
    # 3. M√°scara de plantas detectadas (multi-nivel)
    ax3 = fig.add_subplot(2, 3, 3)
    ax3.imshow(mask_plants, cmap='gray')
    ax3.set_title("M√°scara de Plantas (Multi-Nivel)", fontsize=16)
    ax3.axis("off")
    
    # 4. Hojas detectadas (m√°scara binaria)
    ax4 = fig.add_subplot(2, 3, 4)
    ax4.imshow(mask_leaves, cmap='gray')
    ax4.set_title("Hojas Detectadas", fontsize=16)
    ax4.axis("off")
    
    # 5. Hojas detectadas (color verde)
    ax5 = fig.add_subplot(2, 3, 5)
    ax5.imshow(cv2.cvtColor(leaves_colored, cv2.COLOR_BGR2RGB))
    ax5.set_title("Hojas Detectadas (Verde)", fontsize=16)
    ax5.axis("off")
    
    # 6. Superposici√≥n en imagen original
    ax6 = fig.add_subplot(2, 3, 6)
    overlay = cv2.addWeighted(original_bgr, 0.6, leaves_colored, 0.4, 0)
    ax6.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))
    ax6.set_title("Superposici√≥n en Original", fontsize=16)
    ax6.axis("off")
    
    plt.tight_layout()
    plt.savefig(save_path, bbox_inches="tight", pad_inches=0.05, dpi=150)
    plt.close(fig)

def process_image_noir_avanzado(image_path: str) -> Dict[str, Any]:
    """Procesa una imagen NIR para detectar hojas verdes con preprocesamiento avanzado."""
    print(f"  Procesando: {os.path.basename(image_path)}")
    
    # Cargar imagen
    bgr = cv2.imread(image_path)
    if bgr is None:
        print(f"    ‚ùå Error: No se pudo cargar la imagen")
        return {}
    
    # Convertir a uint8 si es necesario (las im√°genes NIR suelen ser float64)
    if bgr.dtype != np.uint8:
        if bgr.dtype == np.float64:
            bgr = (bgr * 255).astype(np.uint8)
        elif bgr.dtype == np.float32:
            bgr = (bgr * 255).astype(np.uint8)
        else:
            bgr = bgr.astype(np.uint8)
        print(f"    üîß Convertida imagen de {bgr.dtype} to uint8")
    
    print("    üîß Aplicando preprocesamiento avanzado NIR...")
    
    # 1. PREPROCESAMIENTO AVANZADO
    bgr_preprocessed = apply_advanced_preprocessing_nir(bgr)
    
    # 2. CONVERTIR A ESCALA DE GRISES PARA SEGMENTACI√ìN NIR
    gray_preprocessed = cv2.cvtColor(bgr_preprocessed, cv2.COLOR_BGR2GRAY)
    print("    üîß Imagen convertida a escala de grises para an√°lisis NIR")
    
    # 3. DEFINICI√ìN DE ROI
    roi_mask, roi_info = define_plant_roi_noir(bgr_preprocessed)
    
    print("     Segmentando hojas verdes usando reflectancia NIR...")
    
    # 4. SEGMENTACI√ìN SIMPLIFICADA CON REFLECTANCIA NIR
    mask_plants, analysis_results = enhanced_green_segmentation_nir(
        gray_preprocessed, roi_mask
    )
    
    # 5. USAR SOLO HOJAS (sin separar tallos)
    mask_leaves = mask_plants.copy()
    
    # 6. C√ÅLCULO DE M√âTRICAS NDVI
    ndvi_metrics = calculate_ndvi_metrics_nir(mask_leaves, bgr_preprocessed)
    
    print("    üíæ Guardando visualizaci√≥n comprehensiva...")
    
    # 7. GUARDAR VISUALIZACI√ìN
    stem = os.path.splitext(os.path.basename(image_path))[0]
    vis_path = os.path.join(OUTPUT_DIR, PROCESSED_DIR, f"{stem}_noir_avanzado.jpg")
    
    # Usar m√©tricas NDVI para la visualizaci√≥n
    leaf_metrics = {
        'numero_plantas': len(ndvi_metrics),
        'area_total_plantas': sum(m['area'] for m in ndvi_metrics),
        'area_promedio_plantas': np.mean([m['area'] for m in ndvi_metrics]) if ndvi_metrics else 0.0,
        'ndvi_promedio': np.mean([m['ndvi_mean'] for m in ndvi_metrics]) if ndvi_metrics else 0.0,
        'ndvi_desv_std': np.mean([m['ndvi_std'] for m in ndvi_metrics]) if ndvi_metrics else 0.0
    }
    
    save_comprehensive_visualization_nir(
        bgr_preprocessed, mask_plants, mask_leaves,
        roi_info, analysis_results, leaf_metrics, vis_path
    )
    
    print(f"     Visualizaci√≥n guardada: {vis_path}")
    
    # 8. PREPARAR DATOS PARA CSV
    timestamp = extract_timestamp(stem)
    
    # Crear fila para cada hoja individual
    rows_data = []
    for i, metrics in enumerate(ndvi_metrics):
        row_data = {
            "imagen": stem,
            "timestamp": timestamp,
            "planta_id": i + 1,
            "numero_plantas_total": len(ndvi_metrics),
            "area": metrics['area'],
            "ndvi_mean": metrics['ndvi_mean'],
            "ndvi_std": metrics['ndvi_std']
        }
        rows_data.append(row_data)
    
    # Si no hay hojas, crear una fila con valores 0
    if not ndvi_metrics:
        row_data = {
            "imagen": stem,
            "timestamp": timestamp,
            "planta_id": 0,
            "numero_plantas_total": 0,
            "area": 0.0,
            "ndvi_mean": 0.0,
            "ndvi_std": 0.0
        }
        rows_data.append(row_data)
    
    return rows_data

def main_noir_avanzado():
    """Funci√≥n principal para procesar im√°genes NIR con preprocesamiento avanzado."""
    ensure_dirs()
    
    # Listar im√°genes
    images = list_images(INPUT_DIR)
    if not images:
        raise FileNotFoundError(f"No hay im√°genes en {INPUT_DIR}")
    
    print(f" PROCESAMIENTO AVANZADO DE IM√ÅGENES NIR")
    print(f" Entrada: {INPUT_DIR}")
    print(f" Salida: {OUTPUT_DIR}/{PROCESSED_DIR}")
    print(f" CSV: {CSV_PATH}")
    print("=" * 60)
    print(" PAR√ÅMETROS DE SEGMENTACI√ìN NIR:")
    print(f"   - √Årea m√≠nima hoja: {MIN_LEAF_AREA} px (ESTRICTO para eliminar puntos falsos)")
    print(f"   - √Årea m√≠nima tallo: {MIN_STEM_AREA} px")
    print(f"   - M√©todo: NDVI (sin par√°metros HSV)")
    print("=" * 60)
    print(" ROIs ADAPTATIVOS: Maceta 1 (arriba, amarilla) y Maceta 2 (abajo, rosada) - Detecci√≥n autom√°tica + coordenadas base como respaldo")
    print(" M√âTRICAS EXTRACTADAS: √Årea, NDVI promedio, NDVI desv_std")
    print(" DETECCI√ìN: Solo hojas verdes (sin tallos)")
    print(" PREPROCESAMIENTO: Balance de blancos + Correcci√≥n de color + CLAHE")
    print(" SEGMENTACI√ìN: Multi-nivel con m√∫ltiples umbrales + combinaci√≥n inteligente")
    print(" FILTRADO MEJORADO: Eliminaci√≥n estricta de objetos ")
    print("=" * 60)
    
    # Procesar im√°genes
    all_rows = []
    for i, image_path in enumerate(images, 1):
        print(f"\n[{i}/{len(images)}] {os.path.basename(image_path)}")
        try:
            resultados = process_image_noir_avanzado(image_path)
            if resultados:
                all_rows.extend(resultados)
                num_hojas = resultados[0]['numero_plantas_total'] if resultados else 0
                print(f"  ‚úÖ Hojas detectadas: {num_hojas}")
            else:
                print("  ‚ö†Ô∏è Sin resultados")
        except Exception as e:
            print(f"  ‚ùå Error: {e}")
            # Crear fila de error
            error_row = {
                "imagen": os.path.basename(image_path),
                "timestamp": None,
                "planta_id": 0,
                "numero_plantas_total": 0,
                "area": 0.0,
                "ndvi_mean": 0.0,
                "ndvi_std": 0.0
            }
            all_rows.append(error_row)
    
    # Guardar CSV
    if all_rows:
        df = pd.DataFrame(all_rows)
        df.to_csv(CSV_PATH, index=False, encoding="utf-8")
        
        print(f"\n PROCESAMIENTO NIR COMPLETADO!")
        print(f"   - CSV: {CSV_PATH}")
        print(f"   - Visualizaciones: {os.path.join(OUTPUT_DIR, PROCESSED_DIR)}")
        
        # Resumen
        print(f"\n RESUMEN NIR:")
        print(f"   - Total de im√°genes: {len(images)}")
        print(f"   - Total de hojas analizadas: {len(all_rows)}")
        print(f"   - Hojas con m√©tricas morfol√≥gicas: {len([r for r in all_rows if r['area'] > 0])}")
        
        if len(all_rows) > 0:
            areas = [r['area'] for r in all_rows if r['area'] > 0]
            if areas:
                print(f"   - √Årea promedio de hojas: {np.mean(areas):.1f} px")
                ndvi_avg = np.mean([r['ndvi_mean'] for r in all_rows if r['ndvi_mean'] != 0])
                ndvi_std_avg = np.mean([r['ndvi_std'] for r in all_rows if r['ndvi_std'] != 0])
                print(f"   - NDVI promedio: {ndvi_avg:.3f}")
                print(f"   - NDVI desv_std promedio: {ndvi_std_avg:.3f}")
    else:
        print("\n No se generaron resultados")

if __name__ == "__main__":
    print(" PLANT CV PROCESAMIENTO NIR AVANZADO - SEGMENTACI√ìN DE HOJAS VERDES")
    print("=" * 80)
    print("Este script incluye:")
    print(" Preprocesamiento avanzado (balance de blancos, correcci√≥n de color, CLAHE)")
    print(" Detecci√≥n autom√°tica de macetas con coordenadas base como respaldo")
    print(" Segmentaci√≥n especializada de hojas verdes en NIR")
    print(" Visualizaci√≥n comprehensiva de 6 paneles")
    print(" M√âTRICAS NDVI DETALLADAS (√çndice de Vegetaci√≥n) para an√°lisis de reflectancia")
    print("=" * 80)
    print(" PROCESANDO: img_noir (im√°genes NIR)")
    print(" SALIDA: output/imagenes_procesadas_noir_avanzado")
    print(" CSV: output/metricas_reflectancia.csv")
    print(" M√âTODO: Reflectancia NIR directa + An√°lisis NDVI + ROIs adaptativos")
    print(" ROIs: Maceta 1 (arriba, amarilla) y Maceta 2 (abajo, rosada) - Detecci√≥n autom√°tica + coordenadas base como respaldo")
    print(" PREPROCESAMIENTO: Balance de blancos + Correcci√≥n de color + CLAHE")
    print(" SEGMENTACI√ìN: An√°lisis directo de reflectancia NIR dentro del ROI")
    print("=" * 80)
    
    try:
        main_noir_avanzado()
    except Exception as e:
        print(f"\n Error en el procesamiento principal: {e}")
        print("\n Para usar el script:")
        print("   1. Coloca tus im√°genes NIR en la carpeta 'img_noir'")
        print("   2. Ejecuta: python rrspaldo.py")
        print("   3. Los resultados se guardar√°n en 'output/imagenes_procesadas_noir_avanzado'")
        print("   4. Las m√©tricas se guardar√°n en 'output/metricas_hsv_noir_avanzado.csv'")

       